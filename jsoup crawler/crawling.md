@ITKOO<br>

# Crawling

- **Topic** : 크롤링의 개념 및 필요성

<br>

**1) 크롤링(Crawling)이란 무엇인가?**

        크롤링(crawling) 혹은 스크레이핑(scraping)이라고 하며,  
        
        웹페이지를 그대로 가져와서 데이터를 추출해내는 행위를 말함.
        
        이런 크롤링을 하는 소프트웨어 == 크롤러(crawler)    
 
<br>


**2) 무엇으로 크롤링 하는건가?**
        
        이 분야에서는 python이 가장 많이 사용되며, 컴퓨터 프로그래밍이 익숙X 않은 비전공자
        
        인문학, 통계 분야 종사자 분들 등이 사용하기 쉽도록 라이브러리들(대표 Beautifulsoup)이 매우 발달되어있음.
        
       ※ python을 제외하고도 java(Jsoup), 브라우저(Seleninum)을 이용해 크롤링을 할 수 있슴.
 
 <br>
        
**3) 크롤링 프로세스는?**
        
        1) 크롤링을 진행할 대상 선정(api or 웹문서?)
        
        2) 데이터 로드 (api라면 xml,json / 웹페이지면 html)
        
        3) 데이터 분석(어떠한 부분이 내게 필요한 정보인지 분석하는 과정 / 필요정보 vs 불필요정보)
        
        4) 수집(데이터 실제 추출 and 저장)

<br>

**cf)  ITKOO의 Driver-Insurance-CrawlerSample 레파지토리를 보면 크롤링을 했던데, 왜 한것인가?**
        
        운전자의 상황에 따라 각기 다른 운전자보험료를 보여주고싶은데, 그때
        
        사용자의 선택정보, 순위, 보험사, 가격등의 정보를 케이스별로 얻기 위해서.
        
        (보험다모아 사이트 크롤링을 진행함.)


<br>

**cf2)  Driver-Insurance-CrawlerSample프로젝트는 어떠한 툴을 사용해 개발했나?**
        
        이 프로젝트는 java를 이용해(spring 사용) 크롤링을 했으며
        
        jsoup 라이브러리를 이용하였음.
        
        - jsoup은 java html parser로써 데이터를 추출하고 조작하기 위해 사용하는 라이브러리,

          DOM, CSS 구조를 이용, jquery와 비슷한 메서드를 가지고 있음.(HTML5 지원)
        

        
        
        
